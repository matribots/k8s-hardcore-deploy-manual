为了方便参考，文档中的一些命令、配置文件中加了注释。在实际部署过程中，需要将这些注释删除，否则运行时会有问题。

&nbsp;

# 1. 前置步骤

- 完成 01.前置准备
- 完成 02. 创建私有CA（单root CA）
- 完成 03. 配置loadbalancer
- 完成 04. 为kubectl配置admin user
- 完成 05. control plane部署：etcd集群部署
- 完成 06. control plane部署：kube-apiserver
- 完成 07. control plane部署：kube-controller-manager

&nbsp;

# 2. 部署kube-scheduler

## 2.1. 创建kube-scheduler证书签名请求

```bash
# ssh operation-machine
$ ssh kube@192.168.1.200

$ mkdir -p /opt/kubernetes/pki/kube-scheduler/cert

$ vim /opt/kubernetes/pki/kube-scheduler/kube-scheduler-csr.json
```

```bash
{
  "CN": "system:kube-scheduler",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "Shanghai",
      "L": "Shanghai",
      "O": "system:kube-scheduler",
      "OU": "System"
    }
  ]
}
```

- 相对于kube-apiserver，kube-scheduler为其客户端，为客户端签发证书可以不指定hosts。

- 证书请求中，CN字段值代表kube-scheduler在k8s系统中的用户， O字段的值代表`system:kube-scheduler`在k8s系统中的Group为`system:kube-scheduler`；而 RBAC 预定义的 ClusterRoleBinding 将用户`system:kube-scheduler` 与 ClusterRole`system:kube-scheduler`绑定，这就赋予了`kube-scheduler`在集群中的对应权限。

## 2.2. 生成kube-scheduler的证书和私钥

```bash
# ssh operation-machine
$ ssh kube@192.168.1.200

$ cfssl gencert \
-ca=/opt/kubernetes/pki/ca/cert/ca.pem \
-ca-key=/opt/kubernetes/pki/ca/cert/ca-key.pem \
-config=/opt/kubernetes/pki/ca/ca-config.json \
-profile=kubernetes /opt/kubernetes/pki/kube-scheduler/kube-scheduler-csr.json | cfssljson -bare /opt/kubernetes/pki/kube-scheduler/cert/kube-scheduler

$ ls /opt/kubernetes/pki/kube-scheduler/cert
... kube-scheduler-key.pem kube-scheduler.pem ...
```

## 2.3. 分发kube-scheduler的证书和私钥

```bash
# ssh operation-machine
$ ssh kube@192.168.1.200

$ ssh kube@192.168.1.204 "mkdir -p /opt/kubernetes/pki/kube-scheduler/cert" && \
  ssh kube@192.168.1.205 "mkdir -p /opt/kubernetes/pki/kube-scheduler/cert" && \
  ssh kube@192.168.1.206 "mkdir -p /opt/kubernetes/pki/kube-scheduler/cert"

$ scp /opt/kubernetes/pki/kube-scheduler/cert/kube-scheduler*.pem kube@192.168.1.204:/opt/kubernetes/pki/kube-scheduler/cert/ && \
  scp /opt/kubernetes/pki/kube-scheduler/cert/kube-scheduler*.pem kube@192.168.1.205:/opt/kubernetes/pki/kube-scheduler/cert/ && \
  scp /opt/kubernetes/pki/kube-scheduler/cert/kube-scheduler*.pem kube@192.168.1.206:/opt/kubernetes/pki/kube-scheduler/cert/
```

## 2.4. 生成kube-scheduler.kubeconfig

```bash
# ssh to operation-machine
$ ssh kube@192.168.1.200

$ kubectl config set-cluster kubernetes --certificate-authority=/opt/kubernetes/pki/ca/cert/ca.pem --embed-certs=true --server=https://192.168.1.210:6443 --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig

$ kubectl config set-credentials kube-scheduler --client-certificate=/opt/kubernetes/pki/kube-scheduler/cert/kube-scheduler.pem --embed-certs=true --client-key=/opt/kubernetes/pki/kube-scheduler/cert/kube-scheduler-key.pem --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig

$ kubectl config set-context default --cluster=kubernetes --user=kube-scheduler --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig

$ kubectl config use-context default --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig
```

## 2.5 分发kube-scheduler.kubeconfig

```bash
# ssh operation-machine
$ ssh kube@192.168.1.200

$ scp /opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig kube@192.168.1.204:/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig && \
  scp /opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig kube@192.168.1.205:/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig && \
  scp /opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig kube@192.168.1.206:/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig
```

## 2.6. 启动kube-scheduler

```bash
# ssh k8s-master-01
$ ssh kube@192.168.1.204

$ /opt/kubernetes/bin/kube-scheduler \
  --authentication-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --authorization-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --bind-address=192.168.1.204 \
  --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --leader-elect=true \
  --v=2
```

```bash
# ssh k8s-master-02
$ ssh kube@192.168.1.205

$ /opt/kubernetes/bin/kube-scheduler \
  --authentication-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --authorization-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --bind-address=192.168.1.205 \
  --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --leader-elect=true \
  --v=2
```

```bash
# ssh k8s-master-03
$ ssh kube@192.168.1.206

$ /opt/kubernetes/bin/kube-scheduler \
  --authentication-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --authorization-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --bind-address=192.168.1.206 \
  --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --leader-elect=true \
  --v=2
```

&nbsp;

# 3. Smoke test

## 3.1. 查看kube-scheduler@k8s-master-01日志

可以看到kube-scheduler在启动中尝试成为leader，由于k8s-master-01上的kube-scheduler是最先启动的，因此它很自然地就成为了leader；启动完毕后，可以看到kube-scheduler开始尝试调度nginx pod；由于目前还没有部署work node，因此pod暂时还无法被调度。

![](../pictures/kube_scheudler_attemping_become_leader_1.jpg)

## 3.2. 查看kube-scheduler@k8s-master-02日志

可以看到k8s-master-02上的kube-scheduler在启动中，尝试成为leader，但并没有成功。这是因为k8s-master-01上的kube-scheduler已经是leader了。

![](../pictures/kube_scheudler_attemping_become_leader_2.jpg)

## 3.3. 查看kube-scheduler@k8s-master-03日志

可以看到k8s-master-03上的kube-scheduler在启动中，尝试成为leader，但并没有成功。这是因为k8s-master-01上的kube-scheduler已经是leader了。

![](../pictures/kube_scheudler_attemping_become_leader_3.jpg)

## 3.4. 通过kubectl查看nginx deployment

此时虽然部署了kube-scheduler，但是由于目前还没有可供调度的节点，因此pod还无法被调度，显示的还是Pending状态。

![](../pictures/kubectl_get_nginx_deployment_and_pod_2.jpg)

## 3.5. 停止kube-scheduler@k8s-master-01

并观察`k8s-master-02`和`k8s-master-03`上的kube-scheduler日志，发现此时`k8s-master-02`上的`kube-scheduler`成为了`leader`。

![](../pictures/kube_scheudler_attemping_become_leader_4.jpg)

## 3.6. 停止kube-scheduler@k8s-master-02

并观察`k8s-master-03`上的kube-scheduler日志，发现此时`k8s-master-03`上的`kube-scheduler`成为了`leader`。

![](../pictures/kube_scheudler_attemping_become_leader_5.jpg)

&nbsp;

根据日志来看，kube-scheduler的leader选举应该也是利用etcd的lease机制来实现的，但这也是目前个人根据观察日志得到的推测，具体还是得去通过查阅源码来验证。

&nbsp;

# 4. 配置system service（optional）

步骤2是以命令行的方式启动，以便在部署过程中观察日志并排障。当部署成功且`smoke test`通过后，可以用`system service`的方式启动，以便测试机器重启后可以自动拉起`kube-scheduler`服务。

## 4.1. 配置kube-scheduler@k8s-master-01系统服务

```bash
# ssh to k8s-master-01
$ ssh kube@192.168.1.204

$ sudo vim /etc/systemd/system/kube-scheduler.service
```

```bash
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
ExecStart=/opt/kubernetes/bin/kube-scheduler \
  --authentication-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --authorization-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --bind-address=192.168.1.204 \
  --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --leader-elect=true \
  --v=2
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```

```bash
$ sudo systemctl enable kube-scheduler.service

$ sudo systemctl daemon-reload && sudo systemctl restart kube-scheduler.service
```

## 4.2. 配置kube-scheduler@k8s-master-02系统服务

```bash
# ssh to k8s-master-02
$ ssh kube@192.168.1.205

$ sudo vim /etc/systemd/system/kube-scheduler.service
```

```bash
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
ExecStart=/opt/kubernetes/bin/kube-scheduler \
  --authentication-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --authorization-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --bind-address=192.168.1.205 \
  --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --leader-elect=true \
  --v=2
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```

```bash
$ sudo systemctl enable kube-scheduler.service

$ sudo systemctl daemon-reload && sudo systemctl restart kube-scheduler.service
```

## 4.3. 配置kube-scheduler@k8s-master-03系统服务

```bash
# ssh to k8s-master-03
$ ssh kube@192.168.1.206

$ sudo vim /etc/systemd/system/kube-scheduler.service
```

```bash
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
ExecStart=/opt/kubernetes/bin/kube-scheduler \
  --authentication-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --authorization-kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --bind-address=192.168.1.206 \
  --kubeconfig=/opt/kubernetes/kubeconfig/kube-scheduler.kubeconfig \
  --leader-elect=true \
  --v=2
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```



```bash
$ sudo systemctl enable kube-scheduler.service

$ sudo systemctl daemon-reload && sudo systemctl restart kube-scheduler.service
```

&nbsp;

至此，K8s control plane的组件已经全部部署完毕。若正常运行，使用kubectl get namespace、clusterrole、clusterrolebinding等，能够获取到系统预定义的资源。甚至用kubectl创建一个Nginx deployment也能成功，只不过pod会一直处于pending状态无法调度，因为还没有部署nodes，kube-scheduler无法将Pod调度到合适的node上。这也从侧面体现出了kubernetes control plane各组件的工作方式及其解耦性。实际上，当部署完kube-apiserver后，就可以用kubectl创建deployment并get相关资源了（元数据层面）。

&nbsp;

# 5. 参考

1. [Kubernetes - PKI certificates and requirements](https://kubernetes.io/docs/setup/best-practices/certificates/)
2. [Kubernetes - Generate Certificates Manually](https://kubernetes.io/docs/tasks/administer-cluster/certificates/)
3. [Kubernetes - 使用 kubeconfig 文件组织集群访问](https://kubernetes.io/zh-cn/docs/concepts/configuration/organize-cluster-access-kubeconfig/)
4. [kubeasz - 生成 kubeconfig 配置文件](https://github.com/easzlab/kubeasz/blob/master/docs/setup/01-CA_and_prerequisite.md#%E7%94%9F%E6%88%90-kubeconfig-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6)
5. [kubeasz - Create kube-scheduler-kubeconfig.yml](https://github.com/easzlab/kubeasz/blob/master/roles/deploy/tasks/create-kube-scheduler-kubeconfig.yml)
6. [kubeasz - kube-scheduler.service.j2](https://github.com/easzlab/kubeasz/blob/master/roles/kube-master/templates/kube-scheduler.service.j2)
